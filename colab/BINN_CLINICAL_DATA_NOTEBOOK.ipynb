{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "d3753b69-165a-41d4-9e19-b0e2f23efebc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=== Clinical BINN Integration ===\n",
      "Generating clinical data...\n",
      "Generated 200 samples with 12 variables\n",
      "Encoding variables...\n",
      "Encoded to 21 features\n",
      "Creating pathways...\n",
      "Created 7 pathway groups\n",
      "Initializing BINN...\n",
      "\n",
      "[INFO] BINN is on device: cpu\n",
      "Mapping group labels: {'high': 0, 'low': 1}\n",
      "Training for 50 epochs...\n",
      "[Epoch 1/50] Train Loss: 0.6793, Train Accuracy: 0.5750\n",
      "[Epoch 1/50] Val Loss: 0.6951, Val Accuracy: 0.4531\n",
      "[Epoch 2/50] Train Loss: 0.6580, Train Accuracy: 0.5938\n",
      "[Epoch 2/50] Val Loss: 0.6926, Val Accuracy: 0.4531\n",
      "[Epoch 3/50] Train Loss: 0.6860, Train Accuracy: 0.6500\n",
      "[Epoch 3/50] Val Loss: 0.6875, Val Accuracy: 0.4531\n",
      "[Epoch 4/50] Train Loss: 0.6709, Train Accuracy: 0.6375\n",
      "[Epoch 4/50] Val Loss: 0.7005, Val Accuracy: 0.4531\n",
      "[Epoch 5/50] Train Loss: 0.6772, Train Accuracy: 0.6125\n",
      "[Epoch 5/50] Val Loss: 0.7081, Val Accuracy: 0.4531\n",
      "[Epoch 6/50] Train Loss: 0.6644, Train Accuracy: 0.6562\n",
      "[Epoch 6/50] Val Loss: 0.7085, Val Accuracy: 0.4531\n",
      "[Epoch 7/50] Train Loss: 0.6774, Train Accuracy: 0.6562\n",
      "[Epoch 7/50] Val Loss: 0.7166, Val Accuracy: 0.4531\n",
      "[Epoch 8/50] Train Loss: 0.6715, Train Accuracy: 0.5875\n",
      "[Epoch 8/50] Val Loss: 0.7341, Val Accuracy: 0.4531\n",
      "[Epoch 9/50] Train Loss: 0.7148, Train Accuracy: 0.4938\n",
      "[Epoch 9/50] Val Loss: 0.7431, Val Accuracy: 0.4531\n",
      "[Epoch 10/50] Train Loss: 0.6731, Train Accuracy: 0.5813\n",
      "[Epoch 10/50] Val Loss: 0.7474, Val Accuracy: 0.4531\n",
      "[Epoch 11/50] Train Loss: 0.6900, Train Accuracy: 0.5938\n",
      "[Epoch 11/50] Val Loss: 0.7469, Val Accuracy: 0.4531\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.12/site-packages/binn/model/dataloader.py:49: FutureWarning: Downcasting object dtype arrays on .fillna, .ffill, .bfill is deprecated and will change in a future version. Call result.infer_objects(copy=False) instead. To opt-in to the future behavior, set `pd.set_option('future.no_silent_downcasting', True)`\n",
      "  dm = dm.reindex(features).fillna(0)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[Epoch 12/50] Train Loss: 0.6776, Train Accuracy: 0.6125\n",
      "[Epoch 12/50] Val Loss: 0.7498, Val Accuracy: 0.4531\n",
      "[Epoch 13/50] Train Loss: 0.6574, Train Accuracy: 0.6937\n",
      "[Epoch 13/50] Val Loss: 0.7476, Val Accuracy: 0.4531\n",
      "[Epoch 14/50] Train Loss: 0.6926, Train Accuracy: 0.6062\n",
      "[Epoch 14/50] Val Loss: 0.7465, Val Accuracy: 0.4531\n",
      "[Epoch 15/50] Train Loss: 0.6779, Train Accuracy: 0.5938\n",
      "[Epoch 15/50] Val Loss: 0.7514, Val Accuracy: 0.4531\n",
      "[Epoch 16/50] Train Loss: 0.6683, Train Accuracy: 0.6500\n",
      "[Epoch 16/50] Val Loss: 0.7520, Val Accuracy: 0.4531\n",
      "[Epoch 17/50] Train Loss: 0.6834, Train Accuracy: 0.5437\n",
      "[Epoch 17/50] Val Loss: 0.7517, Val Accuracy: 0.4531\n",
      "[Epoch 18/50] Train Loss: 0.6798, Train Accuracy: 0.6250\n",
      "[Epoch 18/50] Val Loss: 0.7514, Val Accuracy: 0.4531\n",
      "[Epoch 19/50] Train Loss: 0.6807, Train Accuracy: 0.6062\n",
      "[Epoch 19/50] Val Loss: 0.7506, Val Accuracy: 0.4531\n",
      "[Epoch 20/50] Train Loss: 0.6585, Train Accuracy: 0.6625\n",
      "[Epoch 20/50] Val Loss: 0.7488, Val Accuracy: 0.4531\n",
      "[Epoch 21/50] Train Loss: 0.6737, Train Accuracy: 0.6250\n",
      "[Epoch 21/50] Val Loss: 0.7491, Val Accuracy: 0.4531\n",
      "[Epoch 22/50] Train Loss: 0.6908, Train Accuracy: 0.6000\n",
      "[Epoch 22/50] Val Loss: 0.7467, Val Accuracy: 0.4531\n",
      "[Epoch 23/50] Train Loss: 0.6875, Train Accuracy: 0.6000\n",
      "[Epoch 23/50] Val Loss: 0.7487, Val Accuracy: 0.4531\n",
      "[Epoch 24/50] Train Loss: 0.6496, Train Accuracy: 0.6500\n",
      "[Epoch 24/50] Val Loss: 0.7477, Val Accuracy: 0.4531\n",
      "[Epoch 25/50] Train Loss: 0.6845, Train Accuracy: 0.5813\n",
      "[Epoch 25/50] Val Loss: 0.7462, Val Accuracy: 0.4531\n",
      "[Epoch 26/50] Train Loss: 0.6889, Train Accuracy: 0.6375\n",
      "[Epoch 26/50] Val Loss: 0.7467, Val Accuracy: 0.4531\n",
      "[Epoch 27/50] Train Loss: 0.6504, Train Accuracy: 0.6375\n",
      "[Epoch 27/50] Val Loss: 0.7480, Val Accuracy: 0.4531\n",
      "[Epoch 28/50] Train Loss: 0.6744, Train Accuracy: 0.6500\n",
      "[Epoch 28/50] Val Loss: 0.7474, Val Accuracy: 0.4531\n",
      "[Epoch 29/50] Train Loss: 0.6736, Train Accuracy: 0.6188\n",
      "[Epoch 29/50] Val Loss: 0.7490, Val Accuracy: 0.4531\n",
      "[Epoch 30/50] Train Loss: 0.6837, Train Accuracy: 0.5813\n",
      "[Epoch 30/50] Val Loss: 0.7481, Val Accuracy: 0.4531\n",
      "[Epoch 31/50] Train Loss: 0.6825, Train Accuracy: 0.5938\n",
      "[Epoch 31/50] Val Loss: 0.7465, Val Accuracy: 0.4531\n",
      "[Epoch 32/50] Train Loss: 0.6754, Train Accuracy: 0.6125\n",
      "[Epoch 32/50] Val Loss: 0.7496, Val Accuracy: 0.4531\n",
      "[Epoch 33/50] Train Loss: 0.6519, Train Accuracy: 0.6125\n",
      "[Epoch 33/50] Val Loss: 0.7491, Val Accuracy: 0.4531\n",
      "[Epoch 34/50] Train Loss: 0.6595, Train Accuracy: 0.6875\n",
      "[Epoch 34/50] Val Loss: 0.7433, Val Accuracy: 0.4531\n",
      "[Epoch 35/50] Train Loss: 0.6701, Train Accuracy: 0.6562\n",
      "[Epoch 35/50] Val Loss: 0.7449, Val Accuracy: 0.4531\n",
      "[Epoch 36/50] Train Loss: 0.6760, Train Accuracy: 0.6062\n",
      "[Epoch 36/50] Val Loss: 0.7441, Val Accuracy: 0.4531\n",
      "[Epoch 37/50] Train Loss: 0.6799, Train Accuracy: 0.5938\n",
      "[Epoch 37/50] Val Loss: 0.7430, Val Accuracy: 0.4531\n",
      "[Epoch 38/50] Train Loss: 0.6792, Train Accuracy: 0.5938\n",
      "[Epoch 38/50] Val Loss: 0.7450, Val Accuracy: 0.4531\n",
      "[Epoch 39/50] Train Loss: 0.6909, Train Accuracy: 0.5875\n",
      "[Epoch 39/50] Val Loss: 0.7441, Val Accuracy: 0.4531\n",
      "[Epoch 40/50] Train Loss: 0.6717, Train Accuracy: 0.5875\n",
      "[Epoch 40/50] Val Loss: 0.7424, Val Accuracy: 0.4531\n",
      "[Epoch 41/50] Train Loss: 0.6905, Train Accuracy: 0.5938\n",
      "[Epoch 41/50] Val Loss: 0.7416, Val Accuracy: 0.4531\n",
      "[Epoch 42/50] Train Loss: 0.6730, Train Accuracy: 0.6000\n",
      "[Epoch 42/50] Val Loss: 0.7425, Val Accuracy: 0.4531\n",
      "[Epoch 43/50] Train Loss: 0.6553, Train Accuracy: 0.6687\n",
      "[Epoch 43/50] Val Loss: 0.7396, Val Accuracy: 0.4531\n",
      "[Epoch 44/50] Train Loss: 0.6605, Train Accuracy: 0.6062\n",
      "[Epoch 44/50] Val Loss: 0.7400, Val Accuracy: 0.4531\n",
      "[Epoch 45/50] Train Loss: 0.6733, Train Accuracy: 0.6250\n",
      "[Epoch 45/50] Val Loss: 0.7400, Val Accuracy: 0.4531\n",
      "[Epoch 46/50] Train Loss: 0.6518, Train Accuracy: 0.6625\n",
      "[Epoch 46/50] Val Loss: 0.7440, Val Accuracy: 0.4531\n",
      "[Epoch 47/50] Train Loss: 0.6787, Train Accuracy: 0.6188\n",
      "[Epoch 47/50] Val Loss: 0.7431, Val Accuracy: 0.4531\n",
      "[Epoch 48/50] Train Loss: 0.6402, Train Accuracy: 0.6250\n",
      "[Epoch 48/50] Val Loss: 0.7431, Val Accuracy: 0.4531\n",
      "[Epoch 49/50] Train Loss: 0.6597, Train Accuracy: 0.6687\n",
      "[Epoch 49/50] Val Loss: 0.7415, Val Accuracy: 0.4531\n",
      "[Epoch 50/50] Train Loss: 0.6663, Train Accuracy: 0.6375\n",
      "[Epoch 50/50] Val Loss: 0.7419, Val Accuracy: 0.4531\n",
      "Files saved to /Users/rohan/Downloads/clinical_binn/\n",
      "\n",
      "Pathway summary:\n",
      "  BASELINE_RISK: 3 features\n",
      "  SOCIAL: 4 features\n",
      "  LIFESTYLE: 4 features\n",
      "  GENETICS: 4 features\n",
      "  CARDIO: 4 features\n",
      "  METABOLIC: 3 features\n",
      "  OTHER: 2 features\n",
      "\n",
      "Total: 21 features across 7 pathways\n",
      "\n",
      "Done!\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import json\n",
    "from binn import BINN, BINNDataLoader, BINNTrainer\n",
    "\n",
    "# TODO: move these to config file later\n",
    "SAMPLE_SIZE = 200\n",
    "EPOCHS = 50\n",
    "\n",
    "def generate_clinical_data(n=200):\n",
    "    \"\"\"Generate dummy clinical data for testing\"\"\"\n",
    "    np.random.seed(42)  # for reproducibility\n",
    "    \n",
    "    data = {}\n",
    "    \n",
    "    # basic demographics\n",
    "    data['sex'] = np.random.choice(['Male', 'Female'], n, p=[0.5, 0.5])\n",
    "    data['age'] = np.random.normal(65, 12, n).clip(18, 95)\n",
    "    data['ethnicity'] = np.random.choice(['White', 'Black', 'Asian', 'Hispanic'], n, p=[0.7, 0.15, 0.1, 0.05])\n",
    "    \n",
    "    # socioeconomic stuff\n",
    "    data['education'] = np.random.choice(['HS', 'College', 'Grad'], n, p=[0.4, 0.4, 0.2])\n",
    "    data['income'] = np.random.lognormal(np.log(50000), 0.6, n).clip(20000, 200000)\n",
    "    \n",
    "    # health metrics\n",
    "    data['bmi'] = np.random.normal(26, 5, n).clip(18, 45)\n",
    "    data['family_history'] = np.random.choice(['Yes', 'No'], n, p=[0.3, 0.7])\n",
    "    data['smoking'] = np.random.choice(['Never', 'Former', 'Current'], n, p=[0.5, 0.3, 0.2])\n",
    "    data['diabetes'] = np.random.choice([1, 0], n, p=[0.15, 0.85])\n",
    "    data['hypertension'] = np.random.choice([1, 0], n, p=[0.25, 0.75])\n",
    "    \n",
    "    # lab values\n",
    "    data['cholesterol'] = np.random.normal(200, 40, n).clip(150, 300)\n",
    "    data['bp_systolic'] = np.random.normal(120, 15, n).clip(90, 180)\n",
    "    \n",
    "    samples = [f'P{i:03d}' for i in range(n)]\n",
    "    \n",
    "    # create outcome - quick and dirty risk model\n",
    "    risk = (0.1 + \n",
    "            0.2 * (data['age'] > 70) + \n",
    "            0.15 * (data['sex'] == 'Male') +\n",
    "            0.1 * (data['smoking'] == 'Current') +\n",
    "            0.08 * data['diabetes'] +\n",
    "            0.05 * (data['bmi'] > 30))\n",
    "    \n",
    "    outcome = np.random.binomial(1, np.clip(risk, 0.05, 0.8), n)\n",
    "    \n",
    "    df = pd.DataFrame(data, index=samples)\n",
    "    \n",
    "    design = pd.DataFrame({\n",
    "        'sample': samples,\n",
    "        'target': outcome,\n",
    "        'group': ['high' if x == 1 else 'low' for x in outcome]\n",
    "    })\n",
    "    \n",
    "    return df, design\n",
    "\n",
    "def encode_data(df):\n",
    "    \"\"\"One-hot encode categoricals, standardize continuous\"\"\"\n",
    "    encoded = pd.DataFrame(index=df.index)\n",
    "    info = {}\n",
    "    \n",
    "    for col in df.columns:\n",
    "        if df[col].dtype == 'object':\n",
    "            # categorical - one hot encode\n",
    "            dummies = pd.get_dummies(df[col], prefix=col)\n",
    "            encoded = pd.concat([encoded, dummies], axis=1)\n",
    "            info[col] = {'type': 'cat', 'levels': list(dummies.columns)}\n",
    "        else:\n",
    "            # continuous - standardize\n",
    "            mean_val = df[col].mean()\n",
    "            std_val = df[col].std()\n",
    "            encoded[col] = (df[col] - mean_val) / std_val\n",
    "            info[col] = {'type': 'cont', 'mean': mean_val, 'std': std_val}\n",
    "    \n",
    "    return encoded, info\n",
    "\n",
    "def create_pathways(encoded_df):\n",
    "    \"\"\"Create pathway assignments\"\"\"\n",
    "    \n",
    "    # basic pathway groups that make sense clinically\n",
    "    groups = {\n",
    "        'BASELINE_RISK': ['age', 'sex_Male', 'sex_Female'],\n",
    "        'SOCIAL': ['education_HS', 'education_College', 'education_Grad', 'income'],\n",
    "        'LIFESTYLE': ['bmi', 'smoking_Never', 'smoking_Former', 'smoking_Current'],\n",
    "        'GENETICS': ['family_history_Yes', 'family_history_No', 'ethnicity_Black', 'ethnicity_Asian'],\n",
    "        'CARDIO': ['bp_systolic', 'cholesterol', 'hypertension', 'age'],\n",
    "        'METABOLIC': ['bmi', 'diabetes', 'cholesterol']\n",
    "    }\n",
    "    \n",
    "    pathway_data = []\n",
    "    for pathway, features in groups.items():\n",
    "        for feat in features:\n",
    "            if feat in encoded_df.columns:\n",
    "                pathway_data.append([feat, pathway])\n",
    "    \n",
    "    # catch any missing features\n",
    "    assigned = set([x[0] for x in pathway_data])\n",
    "    for col in encoded_df.columns:\n",
    "        if col not in assigned:\n",
    "            pathway_data.append([col, 'OTHER'])  # general bucket\n",
    "    \n",
    "    return pd.DataFrame(pathway_data, columns=['source', 'target'])\n",
    "\n",
    "def create_mapping(encoded_df):\n",
    "    \"\"\"Create identity mapping for BINN\"\"\"\n",
    "    mapping_data = []\n",
    "    for feat in encoded_df.columns:\n",
    "        mapping_data.append([\n",
    "            feat, feat, \n",
    "            f\"https://reactome.org/{feat}\",  # dummy URL\n",
    "            f\"Clinical: {feat}\", \n",
    "            \"direct\", \"human\"\n",
    "        ])\n",
    "    \n",
    "    return pd.DataFrame(mapping_data, \n",
    "                       columns=[\"input\", \"translation\", \"url\", \"name\", \"x\", \"species\"])\n",
    "\n",
    "def run_binn_integration():\n",
    "    \"\"\"Main integration function\"\"\"\n",
    "    \n",
    "    print(\"Generating clinical data...\")\n",
    "    clinical_df, design_df = generate_clinical_data(SAMPLE_SIZE)\n",
    "    print(f\"Generated {len(clinical_df)} samples with {len(clinical_df.columns)} variables\")\n",
    "    \n",
    "    print(\"Encoding variables...\")\n",
    "    encoded_df, var_info = encode_data(clinical_df)\n",
    "    print(f\"Encoded to {len(encoded_df.columns)} features\")\n",
    "    \n",
    "    print(\"Creating pathways...\")\n",
    "    pathways_df = create_pathways(encoded_df)\n",
    "    print(f\"Created {len(pathways_df['target'].unique())} pathway groups\")\n",
    "    \n",
    "    mapping_df = create_mapping(encoded_df)\n",
    "    \n",
    "    # prep for BINN - need this weird Protein column\n",
    "    data_matrix = encoded_df.copy()\n",
    "    data_matrix['Protein'] = encoded_df.columns[0]  # just use first column\n",
    "    \n",
    "    print(\"Initializing BINN...\")\n",
    "    binn = BINN(\n",
    "        data_matrix=data_matrix,\n",
    "        mapping=mapping_df,\n",
    "        pathways=pathways_df,\n",
    "        n_layers=3,\n",
    "        dropout=0.2\n",
    "    )\n",
    "    \n",
    "    # format data for BINN dataloader - features need to be rows\n",
    "    data_for_loader = data_matrix.drop('Protein', axis=1).T\n",
    "    data_for_loader['Protein'] = data_for_loader.index\n",
    "    \n",
    "    dataloader = BINNDataLoader(binn)\n",
    "    dataloaders = dataloader.create_dataloaders(\n",
    "        data_matrix=data_for_loader,\n",
    "        design_matrix=design_df,\n",
    "        feature_column=\"Protein\",\n",
    "        group_column=\"group\", \n",
    "        sample_column=\"sample\",\n",
    "        batch_size=32,\n",
    "        validation_split=0.2\n",
    "    )\n",
    "    \n",
    "    print(f\"Training for {EPOCHS} epochs...\")\n",
    "    trainer = BINNTrainer(binn)\n",
    "    trainer.fit(dataloaders=dataloaders, num_epochs=EPOCHS)\n",
    "    \n",
    "    return {\n",
    "        'model': binn,\n",
    "        'trainer': trainer,\n",
    "        'data': clinical_df,\n",
    "        'encoded': encoded_df,\n",
    "        'pathways': pathways_df,\n",
    "        'mapping': mapping_df,\n",
    "        'design': design_df\n",
    "    }\n",
    "\n",
    "def save_outputs(results, output_dir='/Users/rohan/Downloads/clinical_binn'):\n",
    "    \"\"\"Save key files\"\"\"\n",
    "    import os\n",
    "    os.makedirs(output_dir, exist_ok=True)\n",
    "    \n",
    "    results['data'].to_csv(f'{output_dir}/clinical_data.csv')\n",
    "    results['encoded'].to_csv(f'{output_dir}/encoded_data.csv') \n",
    "    results['pathways'].to_csv(f'{output_dir}/pathways.csv', index=False)\n",
    "    results['mapping'].to_csv(f'{output_dir}/mapping.csv', index=False)\n",
    "    results['design'].to_csv(f'{output_dir}/design_matrix.csv', index=False)\n",
    "    \n",
    "    print(f\"Files saved to {output_dir}/\")\n",
    "\n",
    "def analyze_results(results):\n",
    "    \"\"\"Quick analysis of results\"\"\"\n",
    "    pathways = results['pathways']\n",
    "    \n",
    "    print(\"\\nPathway summary:\")\n",
    "    for pathway in pathways['target'].unique():\n",
    "        count = len(pathways[pathways['target'] == pathway])\n",
    "        print(f\"  {pathway}: {count} features\")\n",
    "    \n",
    "    print(f\"\\nTotal: {len(results['encoded'].columns)} features across {len(pathways['target'].unique())} pathways\")\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    print(\"=== Clinical BINN Integration ===\")\n",
    "    \n",
    "    # run the integration\n",
    "    results = run_binn_integration()\n",
    "    \n",
    "    # save outputs\n",
    "    save_outputs(results)\n",
    "    \n",
    "    # quick analysis\n",
    "    analyze_results(results)\n",
    "    \n",
    "    print(\"\\nDone!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0c18137c-8c21-47a3-a0ad-e2e21938a95f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/Users/rohan\n"
     ]
    }
   ],
   "source": [
    "! pwd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dfc744ca-3b0a-4416-a9fc-63611e5e3d94",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python [conda env:base] *",
   "language": "python",
   "name": "conda-base-py"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
